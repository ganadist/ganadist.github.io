<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ganachoco's Blog - tech</title><link href="http://ganadist.github.io/" rel="alternate"></link><link href="http://ganadist.github.io/feeds/tech.atom.xml" rel="self"></link><id>http://ganadist.github.io/</id><updated>2018-09-11T23:17:00+09:00</updated><entry><title>Systemd 로 docker-compose 간단하게 관리하기</title><link href="http://ganadist.github.io/2018_09_11_systemd_docker_compose.html" rel="alternate"></link><published>2018-09-11T23:17:00+09:00</published><updated>2018-09-11T23:17:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-09-11:/2018_09_11_systemd_docker_compose.html</id><summary type="html">&lt;p&gt;systemd와 docker-compose를 이용해 gitlab 인스턴스&amp;nbsp;관리하기&lt;/p&gt;</summary><content type="html">&lt;p&gt;회사에서 가지고 노는(?) 일부 서비스는 &lt;a href="https://docs.docker.com/compose/overview/"&gt;docker-compose&lt;/a&gt;를 이용해 관리를 하는데, 가끔씩 docker 이미지를 업그레이드 할 필요가 있습니다.
docker-compose 명령을 이용하면 간단하게 업그레이드 할 수 있긴 하지만, systemd 서비스 형식을 이용하면 왠지 더 뽀대나고, 편하게 관리할 수 있을 것 같다는 생각이 들어서 시도해보았습니다. (덤으로 ubuntu 18.04부터는 systemd로 서비스 관리가&amp;nbsp;됩니다.)&lt;/p&gt;
&lt;p&gt;다음은 docker-compose 를 수행할 systemd service unit 파일 (&lt;code&gt;/etc/systemd/system/docker-compose@.service&lt;/code&gt;)입니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Start docker instance with composer.yml&lt;/span&gt;
&lt;span class="na"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;network.target&lt;/span&gt;
&lt;span class="na"&gt;RequiresMountsFor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/srv&lt;/span&gt;

&lt;span class="k"&gt;[Service]&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;oneshot&lt;/span&gt;
&lt;span class="na"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;-/usr/bin/docker-compose down&lt;/span&gt;
&lt;span class="na"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;-/usr/bin/docker-compose pull&lt;/span&gt;
&lt;span class="na"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/bin/docker-compose up -d&lt;/span&gt;
&lt;span class="na"&gt;WorkingDirectory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/etc/docker-compose/%i&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;ExecStartPre&lt;/code&gt; 에서 업데이트할 도커 이미지가 있는지 확인한 후 업그레이드를 하고, (실패하더라도 fallback 으로 무시) docker-compose를 이용해 인스턴스를 시작합니다.
docker-compose에 필요한 &lt;code&gt;compose.yml&lt;/code&gt;은 &lt;code&gt;/etc/docker-compose/ 의 하위 디렉토리&lt;/code&gt;에 찾을 수 있게 &lt;code&gt;WorkingDirectory&lt;/code&gt;를&amp;nbsp;설정하였습니다.&lt;/p&gt;
&lt;p&gt;아래는 gitlab 을 띄우기 위한 &lt;code&gt;/etc/docker-compose/gitlab/compose.yml&lt;/code&gt; 파일입니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# vim: ts=2 sw=2 sts=2 et ai
gitlab:
  image: gitlab/gitlab-ce:latest
  restart: always
  hostname: gitlab.private
  container_name: gitlab
  environment:
    GITLAB_OMNIBUS_CONFIG: |
      external_url &amp;#39;http://gitlab.example.com/&amp;#39;
      # Add any other gitlab.rb configuration here, each on its own line
      gitlab_rails[&amp;#39;ldap_enabled&amp;#39;] = true
      gitlab_rails[&amp;#39;ldap_servers&amp;#39;] = YAML.load &amp;lt;&amp;lt;-&amp;#39;EOS&amp;#39;
      main: # &amp;#39;main&amp;#39; is the GitLab &amp;#39;provider ID&amp;#39; of this LDAP server
        label: &amp;#39;LDAP&amp;#39;
        host: &amp;#39;ldap.example.com&amp;#39;
        port: 389
        uid: &amp;#39;uid&amp;#39;
        bind_dn: &amp;#39;cn=admin,dc=example,dc=com&amp;#39;
        password: &amp;#39;ldapadminpassword&amp;#39;
        encryption: &amp;#39;plain&amp;#39; # &amp;quot;start_tls&amp;quot; or &amp;quot;simple_tls&amp;quot; or &amp;quot;plain&amp;quot;
        verify_certificates: false
        active_directory: false
        allow_username_or_email_login: true
        lowercase_usernames: true
        block_auto_created_users: false
        base: &amp;#39;ou=members,dc=example,dc=com&amp;#39;
        user_filter: &amp;#39;&amp;#39;
        attributes:
            username: [&amp;#39;uid&amp;#39;]
            email: [&amp;#39;mail&amp;#39;]
            name: &amp;#39;cn&amp;#39;
        ## EE only
        group_base: &amp;#39;&amp;#39;
        admin_group: &amp;#39;&amp;#39;
        sync_ssh_keys: false
      EOS
  ports:
    - &amp;quot;127.0.0.1:8080:80&amp;quot;
  volumes:
    - /etc/gitlab:/etc/gitlab
    - /var/log/gitlab:/var/log/gitlab
    - /srv/gitlab/data:/var/opt/gitlab
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;docker 인스턴스의 lifecycle은 docker service에서 해주며, compose.yml에서 docker 서비스가 시작하면 인스턴스가 자동으로 시작하도록 &lt;code&gt;restart: always&lt;/code&gt;로 설정했기 때문에, systemd의 Service Type은 oneshot으로 설정했습니다. 앞에서도 언급했지만 systemd unit의 역할은 &lt;code&gt;docker 이미지의 업데이트&lt;/code&gt; 스크립트&amp;nbsp;입니다.&lt;/p&gt;
&lt;p&gt;이제 gitlab 인스턴스를 구동시키다가, 업데이트가 필요하면, 다음과 같이 systemd service를 실행해서 docker 이미지를 업데이트하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo systemctl restart docker-compose@gitlab
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;참쉽죠?&lt;/p&gt;</content><category term="systemd"></category><category term="docker"></category><category term="docker-compose"></category><category term="gitlab"></category></entry><entry><title>android 의 dumpsys를 이용한 분석 방법</title><link href="http://ganadist.github.io/2018_07_10_dumpsys.html" rel="alternate"></link><published>2018-07-10T21:16:00+09:00</published><updated>2018-07-10T21:16:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-07-10:/2018_07_10_dumpsys.html</id><summary type="html">&lt;p&gt;android dumpsys&amp;nbsp;사용하기&lt;/p&gt;</summary><content type="html">&lt;p&gt;얼마 전에 &lt;a href="http://pluu.github.io/"&gt;과일님&lt;/a&gt;이 &lt;a href="https://yanolja.github.io/2018/07/Android-Why"&gt;쌩고생하며 디버깅했던 경험을 공유&lt;/a&gt;해주었는데, 약간 더 곁들여서&amp;nbsp;끄적여봅니다.&lt;/p&gt;
&lt;h1&gt;dumpsys&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://developer.android.com/studio/command-line/dumpsys"&gt;dumpsys 명령어&lt;/a&gt;는 IBinder의 &lt;a href="http://bit.ly/2u8AZIY"&gt;dump 메소드&lt;/a&gt;의 결과를 표준 출력으로 출력해주는 유용한 개발도구입니다. adb만 사용 가능한 상태면 손쉽게 기기의 상태를 확인해볼 수 있고, PC가 없더라도 &lt;a href="https://developer.android.com/studio/debug/bug-report#bugreportdevice"&gt;개발자 옵션에 포함되어 있는 버그 신고&lt;/a&gt; 기능을 이용해서 출력을 뽑아낼 수 있습니다. 그런데 아무 IBinder 객체에게 사용할 수 있는 것은 아니고, &lt;a href="https://android.googlesource.com/platform/frameworks/native/+/master/cmds/servicemanager/"&gt;system service manager&lt;/a&gt;에 등록된 항목에 한해서 가능합니다. system service manager에 등록된 IBinder객체는 다음의 명령을 이용해&amp;nbsp;확인가능합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## android 4.3 이전
$ adb shell service list

## android 4.4 이후
$ adb shell dumpsys -l
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;출력물은 각 시스템 서비스의 dump 메소드의 구현을 확인하면 정확하게 어떤 값을 출력하는 지 알 수 있습니다. 예를 들면 다음과&amp;nbsp;같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://android.googlesource.com/platform/frameworks/base/+/079f03f/services/core/java/com/android/server/am/ActivityManagerService.java#15068"&gt;ActivityManagerService&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://android.googlesource.com/platform/frameworks/av/+/1ec73be/media/libmediaplayerservice/MediaPlayerService.cpp#433"&gt;MediaPlayserService&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;dumpsys activity&amp;nbsp;service&lt;/h1&gt;
&lt;p&gt;그리고 &lt;a href="https://developer.android.com/reference/android/app/Service"&gt;앱에서 작성하는 Service 클래스&lt;/a&gt;에도 시스템 서비스와 유사하게 &lt;a href="http://bit.ly/2L3Ty7D"&gt;dump 메소드 인터페이스가 제공&lt;/a&gt;됩니다. 위에 이야기했듯이 dumpsys는 system service manager에 등록된 IBinder 객체에만 접근할 수 있기 때문에, 앱에서 작성한 서비스에서 정보를 얻기 위해서는 ActivityManagerService를 경유해야&amp;nbsp;합니다.&lt;/p&gt;
&lt;p&gt;Android에서 ActivityManagerService는 앱에 포함된 activity, service, broadcast receiver, provider등을 관리해주며, 각 컴포넌트의 상태를 확인할 수 있는데요. dumpsys 명령을 이용하면 정말 상세하게 알 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ adb shell dumpsys activity -h

Activity manager dump options:
  &lt;span class="o"&gt;[&lt;/span&gt;-a&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-c&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-p PACKAGE&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-h&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;WHAT&lt;span class="o"&gt;]&lt;/span&gt; ...
  WHAT may be one of:
    a&lt;span class="o"&gt;[&lt;/span&gt;ctivities&lt;span class="o"&gt;]&lt;/span&gt;: activity stack state
    r&lt;span class="o"&gt;[&lt;/span&gt;recents&lt;span class="o"&gt;]&lt;/span&gt;: recent activities state
    b&lt;span class="o"&gt;[&lt;/span&gt;roadcasts&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;history&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-s&lt;span class="o"&gt;]]&lt;/span&gt;: broadcast state
    broadcast-stats &lt;span class="o"&gt;[&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;]&lt;/span&gt;: aggregated broadcast statistics
    i&lt;span class="o"&gt;[&lt;/span&gt;ntents&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;]&lt;/span&gt;: pending intent state
    p&lt;span class="o"&gt;[&lt;/span&gt;rocesses&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;]&lt;/span&gt;: process state
    o&lt;span class="o"&gt;[&lt;/span&gt;om&lt;span class="o"&gt;]&lt;/span&gt;: out of memory management
    perm&lt;span class="o"&gt;[&lt;/span&gt;issions&lt;span class="o"&gt;]&lt;/span&gt;: URI permission grant state
    prov&lt;span class="o"&gt;[&lt;/span&gt;iders&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;COMP_SPEC ...&lt;span class="o"&gt;]&lt;/span&gt;: content provider state
    provider &lt;span class="o"&gt;[&lt;/span&gt;COMP_SPEC&lt;span class="o"&gt;]&lt;/span&gt;: provider client-side state
    s&lt;span class="o"&gt;[&lt;/span&gt;ervices&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;COMP_SPEC ...&lt;span class="o"&gt;]&lt;/span&gt;: service state
    as&lt;span class="o"&gt;[&lt;/span&gt;sociations&lt;span class="o"&gt;]&lt;/span&gt;: tracked app associations
    settings: currently applied config settings
    service &lt;span class="o"&gt;[&lt;/span&gt;COMP_SPEC&lt;span class="o"&gt;]&lt;/span&gt;: service client-side state
    package &lt;span class="o"&gt;[&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;]&lt;/span&gt;: all state related to given package
    all: dump all activities
    top: dump the top activity
  WHAT may also be a COMP_SPEC to dump activities.
  COMP_SPEC may be a component name &lt;span class="o"&gt;(&lt;/span&gt;com.foo/.myApp&lt;span class="o"&gt;)&lt;/span&gt;,
    a partial substring in a component name, a
    hex object identifier.
  -a: include all available server state.
  -c: include client state.
  -p: limit output to given package.
  --checkin: output checkin format, resetting data.
  --C: output checkin format, not resetting data.
  --proto: output dump in protocol buffer format.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;여기서 특정 앱의 service에 포함된 dump 메소드(&lt;a href="https://android.googlesource.com/platform/frameworks/base/+/079f03f/packages/SystemUI/src/com/android/systemui/SystemUIService.java#47"&gt;SystemUI&lt;/a&gt; 또는 &lt;a href="https://android.googlesource.com/platform/packages/services/Telephony/+/67a453d/src/com/android/phone/TelephonyDebugService.java#51"&gt;TelephonyService&lt;/a&gt;)의 출력 결과를 알고 싶다면 다음과 같이 명령을 실행하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ adb shell dumpsys activity service com.android.systemui/.SystemUIService

$ adb shell dumpsys activity service com.android.phone/.TelephonyDebugService
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;만약에 여러분이 작성한 앱의 서비스에서 다양한 디버깅 정보를 출력하고 싶다면, dump메소드를 채우면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;h1&gt;dumpsys activity&amp;nbsp;broadcasts&lt;/h1&gt;
&lt;p&gt;intent broadcast 타이밍 때문에 고통받는 개발자들도 dumpsys를 이용하면 큰 도움이&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;다음의 명령을 이용하면 intent broadcast가 발생했던 시간, intent 내용 및 처리 시간과 receiver 등을 쉽게 확인해볼 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ adb shell dumpsys activity broadcasts &lt;span class="nb"&gt;history&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="android"></category></entry><entry><title>gerrit의 database를 h2에서 pgsql로 변환하기</title><link href="http://ganadist.github.io/2018_06_10_gerrit_h2_pgsql_convert.html" rel="alternate"></link><published>2018-06-10T22:56:00+09:00</published><updated>2018-06-10T22:56:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-06-10:/2018_06_10_gerrit_h2_pgsql_convert.html</id><summary type="html">&lt;p&gt;gerrit database를 h2에서 pgsql로&amp;nbsp;바꾸기&lt;/p&gt;</summary><content type="html">&lt;p&gt;1달 전에 설치했던 회사 &lt;a href="https://www.gerritcodereview.com/"&gt;gerrit&lt;/a&gt;서비스의 성능을 튜닝해보던 중, 별도로 database 설치 및 설정이 귀찮아서 gerrit에서 내장으로 제공되는 &lt;a href="http://www.h2database.com/"&gt;h2 database&lt;/a&gt;를 선택하던게 문제가 있지 않나 싶은 의심이 들어서, gerrit 관리자들 사이에서 널리 사용되는 &lt;a href="https://www.postgresql.org/"&gt;postgresql&lt;/a&gt;로 변환해보기로&amp;nbsp;했습니다.&lt;/p&gt;
&lt;p&gt;database는 전혀 문외한이라 어떻게 해볼까 고민이었는데, 선지자들의 발자취를 검색해보던 중 &lt;a href="https://groups.google.com/forum/#!msg/repo-discuss/waUyfJ6pbf0/wQnpu9EIAgAJ"&gt;google groups&lt;/a&gt;에 다행히 성공담이 남아있길래, 그들의 작업 로그를 기반으로 진행해보았습니다. google groups에 논의된 백업 방법은 gerrit 2.7 및 2.12 버젼 기반이고, 제 경우에는 현재 제일 최근 버젼인 2.15를 기반으로&amp;nbsp;진행하였습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;주의&lt;/strong&gt;: 잘못 건드렸다간 데이터를 날려먹을 수 있기 때문에 꼭 이전 데이터를 백업해두시기 바랍니다. 저는 tar로 묶어서 안전하게 보관한 후 진행을&amp;nbsp;시작했습니다.&lt;/p&gt;
&lt;h2&gt;h2 database를 csv로&amp;nbsp;export&lt;/h2&gt;
&lt;p&gt;먼저 h2 database에서 내장 함수를 이용해 csv로 export를 하였습니다. google groups의 예제에서는 한땀한땀 h2의 내장 함수를 실행시켜주었지만, python 스크립트를 이용해 일괄적으로 csv 파일로 변환했습니다. (gerrit 버젼에 따라서 table 및 column 이름이 바뀔 수&amp;nbsp;있습니다.)&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/0c2780a1f3a624041665e971c5ea632f.js?file=gerrit_h2_to_csv.py'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3
# vim: ts=4 sw=4 sts=4 et ai
import os, sys
import subprocess

tables = {
'ACCOUNT_EXTERNAL_IDS':
  ("ACCOUNT_ID","EMAIL_ADDRESS","PASSWORD","EXTERNAL_ID"),
'ACCOUNT_GROUP_BY_ID':
  ("GROUP_ID","INCLUDE_UUID"),
'ACCOUNT_GROUP_BY_ID_AUD':
  ("ADDED_BY","REMOVED_BY","REMOVED_ON","GROUP_ID","INCLUDE_UUID","ADDED_ON"),
'ACCOUNT_GROUP_MEMBERS':
  ("ACCOUNT_ID","GROUP_ID"),
'ACCOUNT_GROUP_MEMBERS_AUDIT':
  ("ADDED_BY","REMOVED_BY","REMOVED_ON","ACCOUNT_ID","GROUP_ID","ADDED_ON"),
'ACCOUNT_GROUP_NAMES':
  ("GROUP_ID","NAME",),
'ACCOUNT_GROUPS':
  ("NAME","DESCRIPTION","VISIBLE_TO_ALL","GROUP_UUID","OWNER_GROUP_UUID","GROUP_ID","CREATED_ON"),
'ACCOUNTS':
  ("REGISTERED_ON","FULL_NAME","PREFERRED_EMAIL","INACTIVE","STATUS","ACCOUNT_ID"),
'CHANGE_MESSAGES':
  ("AUTHOR_ID","WRITTEN_ON","MESSAGE","PATCHSET_CHANGE_ID","PATCHSET_PATCH_SET_ID","TAG","REAL_AUTHOR","CHANGE_ID","UUID"),
'CHANGES':
  ("CHANGE_KEY","CREATED_ON","LAST_UPDATED_ON","OWNER_ACCOUNT_ID","DEST_PROJECT_NAME","DEST_BRANCH_NAME","STATUS","CURRENT_PATCH_SET_ID","SUBJECT","TOPIC","ORIGINAL_SUBJECT","SUBMISSION_ID","ASSIGNEE","NOTE_DB_STATE","ROW_VERSION","CHANGE_ID","IS_PRIVATE","WORK_IN_PROGRESS","REVIEW_STARTED","REVERT_OF"),
'PATCH_COMMENTS':
  ("LINE_NBR","AUTHOR_ID","WRITTEN_ON","STATUS","SIDE","MESSAGE","PARENT_UUID","RANGE_START_LINE","RANGE_START_CHARACTER","RANGE_END_LINE","RANGE_END_CHARACTER","TAG","REAL_AUTHOR","UNRESOLVED","CHANGE_ID","PATCH_SET_ID","FILE_NAME","UUID"),
'PATCH_SET_APPROVALS':
  ("VALUE","GRANTED","TAG","REAL_ACCOUNT_ID","POST_SUBMIT","CHANGE_ID","PATCH_SET_ID","ACCOUNT_ID","CATEGORY_ID"),
'PATCH_SETS':
  ("REVISION","UPLOADER_ACCOUNT_ID","CREATED_ON","GROUPS","PUSH_CERTIFICATE","DESCRIPTION","CHANGE_ID","PATCH_SET_ID"),
'SCHEMA_VERSION':
  ("VERSION_NBR","SINGLETON"),
'SYSTEM_CONFIG':
  ("REGISTER_EMAIL_PRIVATE_KEY","SITE_PATH","ADMIN_GROUP_ID","ANONYMOUS_GROUP_ID","REGISTERED_GROUP_ID","WILD_PROJECT_NAME","BATCH_USERS_GROUP_ID","OWNER_GROUP_ID","ADMIN_GROUP_UUID","BATCH_USERS_GROUP_UUID","SINGLETON")
}

def dump_table(table_name):
    filename = os.path.join('/srv/gerrit/csv', table_name)
    cols = tables[table_name]
    cols = ','.join(cols)
    cmd = f"call csvwrite('{filename}', 'select {cols} from {table_name}');"
    return cmd

def dump_currval(id_name):
    cmd = f"select currval('{id_name}');"
    return cmd

def dump():
    for table_name in tables:
        yield dump_table(table_name)
    for id_name in ('change_id', 'account_id', 'account_group_id'):
        yield dump_currval(id_name)

def main():
    cmd = 'java', '-jar', 'bin/gerrit.war', 'gsql', '-d', '.'
    with subprocess.Popen(cmd,
            bufsize = 0, universal_newlines = True,
            stdin = subprocess.PIPE) as proc:
        for cmd in dump():
            proc.stdin.write(cmd + '\r\n')
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;스크립트 수행 결과 말미의 sequence는 따로 보관하기가 귀찮아서, 수동으로 import 스크립트에 박아서&amp;nbsp;처리했습니다.&lt;/p&gt;
&lt;h2&gt;All-Projcts 및 All-Users repository&amp;nbsp;백업&lt;/h2&gt;
&lt;p&gt;일단 csv로 export가 완료되면, gerrit 에서 자동으로 생성되었던 &lt;strong&gt;All-Projects.git&lt;/strong&gt; 및 &lt;strong&gt;All-Users.git&lt;/strong&gt; repository 를 별도로 백업해두어야 합니다. 해당 repository에는 전체 프로젝트 및 사용자의 권한 정보가 보관되고, 이후에 db를 생성하기 위해 gerrit을 재초기화 할 때 같이 초기화가 되기 때문에, 꼭 백업을 해두었다가 다시 활용해야&amp;nbsp;합니다.&lt;/p&gt;
&lt;h2&gt;이전할 database로 gerrit 재&amp;nbsp;초기화&lt;/h2&gt;
&lt;p&gt;배포판에서 제공하는 pgsql을 설치한 후, &lt;a href="https://gerrit-review.googlesource.com/Documentation/install.html#createdb_postgres"&gt;database의 user 및 table을 구성&lt;/a&gt;하고 &lt;a href="https://gerrit-review.googlesource.com/Documentation/config-gerrit.html#database"&gt;gerrit 설정&lt;/a&gt;에서 pgsql을 사용하도록 구성한 다음 재 초기화를&amp;nbsp;진행합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -jar bin/gerrit.war init --batch -d .
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;All-Projects 및 All-Users repository&amp;nbsp;복구&lt;/h2&gt;
&lt;p&gt;앞에서 백업해두었던 두 개의 repository를 다시 원래 위치에 복사해서&amp;nbsp;복구합니다.&lt;/p&gt;
&lt;h2&gt;csv를 pgsql로&amp;nbsp;import&lt;/h2&gt;
&lt;p&gt;h2를 export할 때와 유사하게 python 스크립트로 구성해서 pgsql에 csv를&amp;nbsp;퍼부었습니다.&lt;/p&gt;
&lt;p&gt;일부 sequence (change_id, account_id, account_group_id)는 h2스크립트에서 출력했던 결과를 수동으로&amp;nbsp;기입했습니다.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/0c2780a1f3a624041665e971c5ea632f.js?file=gerrit_csv_to_pgsql.py'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3
# vim: ts=4 sw=4 sts=4 et ai
import os, sys
import subprocess

tables = {
'ACCOUNT_EXTERNAL_IDS':
  ("ACCOUNT_ID","EMAIL_ADDRESS","PASSWORD","EXTERNAL_ID"),
'ACCOUNT_GROUP_BY_ID':
  ("GROUP_ID","INCLUDE_UUID"),
'ACCOUNT_GROUP_BY_ID_AUD':
  ("ADDED_BY","REMOVED_BY","REMOVED_ON","GROUP_ID","INCLUDE_UUID","ADDED_ON"),
'ACCOUNT_GROUP_MEMBERS':
  ("ACCOUNT_ID","GROUP_ID"),
'ACCOUNT_GROUP_MEMBERS_AUDIT':
  ("ADDED_BY","REMOVED_BY","REMOVED_ON","ACCOUNT_ID","GROUP_ID","ADDED_ON"),
'ACCOUNT_GROUP_NAMES':
  ("GROUP_ID","NAME",),
'ACCOUNT_GROUPS':
  ("NAME","DESCRIPTION","VISIBLE_TO_ALL","GROUP_UUID","OWNER_GROUP_UUID","GROUP_ID","CREATED_ON"),
'ACCOUNTS':
  ("REGISTERED_ON","FULL_NAME","PREFERRED_EMAIL","INACTIVE","STATUS","ACCOUNT_ID"),
'CHANGE_MESSAGES':
  ("AUTHOR_ID","WRITTEN_ON","MESSAGE","PATCHSET_CHANGE_ID","PATCHSET_PATCH_SET_ID","TAG","REAL_AUTHOR","CHANGE_ID","UUID"),
'CHANGES':
  ("CHANGE_KEY","CREATED_ON","LAST_UPDATED_ON","OWNER_ACCOUNT_ID","DEST_PROJECT_NAME","DEST_BRANCH_NAME","STATUS","CURRENT_PATCH_SET_ID","SUBJECT","TOPIC","ORIGINAL_SUBJECT","SUBMISSION_ID","ASSIGNEE","NOTE_DB_STATE","ROW_VERSION","CHANGE_ID","IS_PRIVATE","WORK_IN_PROGRESS","REVIEW_STARTED","REVERT_OF"),
'PATCH_COMMENTS':
  ("LINE_NBR","AUTHOR_ID","WRITTEN_ON","STATUS","SIDE","MESSAGE","PARENT_UUID","RANGE_START_LINE","RANGE_START_CHARACTER","RANGE_END_LINE","RANGE_END_CHARACTER","TAG","REAL_AUTHOR","UNRESOLVED","CHANGE_ID","PATCH_SET_ID","FILE_NAME","UUID"),
'PATCH_SET_APPROVALS':
  ("VALUE","GRANTED","TAG","REAL_ACCOUNT_ID","POST_SUBMIT","CHANGE_ID","PATCH_SET_ID","ACCOUNT_ID","CATEGORY_ID"),
'PATCH_SETS':
  ("REVISION","UPLOADER_ACCOUNT_ID","CREATED_ON","GROUPS","PUSH_CERTIFICATE","DESCRIPTION","CHANGE_ID","PATCH_SET_ID"),
'SCHEMA_VERSION':
  ("VERSION_NBR","SINGLETON"),
'SYSTEM_CONFIG':
  ("REGISTER_EMAIL_PRIVATE_KEY","SITE_PATH","ADMIN_GROUP_ID","ANONYMOUS_GROUP_ID","REGISTERED_GROUP_ID","WILD_PROJECT_NAME","BATCH_USERS_GROUP_ID","OWNER_GROUP_ID","ADMIN_GROUP_UUID","BATCH_USERS_GROUP_UUID","SINGLETON")
}

SEQUENCES = {
  'change_id': 'NNNN', # change_id sequence from gerrit_h2_to_csv.py
  'account_id': '10000XX', # account_id sequence from gerrit_h2_to_csv.py
  'account_group_id': 'GG', # account_group_id sequence from gerrit_h2_to_csv.py
}

def imp_table(table_name):
    filename = os.path.join('/srv/gerrit/csv', table_name)
    cols = tables[table_name]
    cols = '(' + ','.join(cols) + ')'
    table_name = table_name.lower()
    yield f"delete from {table_name};"
    yield f"\COPY {table_name}{cols} from '{filename}' DELIMITER ',' CSV HEADER;"

def imp_currval(id_name):
    value = SEQUENCES[id_name]
    cmd = f"select setval('{id_name}', {value});"
    return cmd

def imp():
    for table_name in tables:
        for cmd in imp_table(table_name):
            yield cmd
    for id_name in ('change_id', 'account_id', 'account_group_id'):
        yield imp_currval(id_name)

def main():
    cmd = 'psql', '-h', 'localhost', '-U', 'gerrit2', 'reviewdb'
    #cmd = 'java', '-jar', 'bin/gerrit.war', 'gsql', '-d', '.'
    with subprocess.Popen(cmd,
            bufsize = 0, universal_newlines = True,
            stdin = subprocess.PIPE) as proc:
        for cmd in imp():
            proc.stdin.write(cmd + '\r\n')
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;gerrit 2.15에서 새로 추가된 &lt;a href="https://gerrit-review.googlesource.com/Documentation/note-db.html"&gt;notedb backend&lt;/a&gt;를 이용하고 있다면 일부 account 관련 database를 import 못한다고 오류가 발생할 수 있는데, 해당 database의 값은 앞에서 복사한 All-Users repository에 포함되어 있기 때문에 무시하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;import가 완료되면 gerrit 내장 sql 커맨드 인터페이스에서 테이블들이 제대로 옮겨졌는지 확인해보면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -jar bin/gerrit.war gsql -d .
gerrit&amp;gt; &lt;span class="se"&gt;\d&lt;/span&gt;
            List of relations
TABLE_SCHEM &lt;span class="p"&gt;|&lt;/span&gt; TABLE_NAME                  &lt;span class="p"&gt;|&lt;/span&gt; TABLE_TYPE
------------+-----------------------------+-----------
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNTS                    &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_EXTERNAL_IDS        &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUPS              &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUP_BY_ID         &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUP_BY_ID_AUD     &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUP_MEMBERS       &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUP_MEMBERS_AUDIT &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; ACCOUNT_GROUP_NAMES         &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; CHANGES                     &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; CHANGE_MESSAGES             &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; PATCH_COMMENTS              &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; PATCH_SETS                  &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; PATCH_SET_APPROVALS         &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; SCHEMA_VERSION              &lt;span class="p"&gt;|&lt;/span&gt; TABLE
PUBLIC      &lt;span class="p"&gt;|&lt;/span&gt; SYSTEM_CONFIG               &lt;span class="p"&gt;|&lt;/span&gt; TABLE

gerrit&amp;gt; &lt;span class="k"&gt;select&lt;/span&gt; * from SCHEMA_VERSION&lt;span class="p"&gt;;&lt;/span&gt;
VERSION_NBR &lt;span class="p"&gt;|&lt;/span&gt; SINGLETON
------------+----------
&lt;span class="m"&gt;161&lt;/span&gt;         &lt;span class="p"&gt;|&lt;/span&gt; X
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; row&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; ms&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;gerrit&amp;nbsp;재시작&lt;/h2&gt;
&lt;p&gt;database 이전이 완료되면 gerrit을 재시작해서 기능이 정상적으로 동작하는지 점검합니다. 혹시 뭔가 이상한 점이 발견되면 맨 앞에서 백업해두었던 tarball을 이용해 되돌리면 손쉽게 복원이 가능합니다&amp;#8230;&amp;nbsp;(무책임)&lt;/p&gt;
&lt;h2&gt;후기&lt;/h2&gt;
&lt;p&gt;이렇게 열과 성의를 다해 database를 이전하였건만, 성능과 관련해서는 딱히 나아진 점이 보이지 않아서, 다시 h2 database로 되돌렸습니다. 그래도 필요하면 언제든지 database 변환이 가능하다는 것을 위안으로&amp;nbsp;삼아야죠.&lt;/p&gt;
&lt;p&gt;gerrit 성능에 대한 삽질은 나중에 기회가 있을 때 이야기를 풀어보도록&amp;nbsp;하겠습니다.&lt;/p&gt;</content><category term="gerrit"></category><category term="database"></category></entry><entry><title>Android 플랫폼 빌드 속도 향상시키기</title><link href="http://ganadist.github.io/2018_06_02_build_performance_enhancement.html" rel="alternate"></link><published>2018-06-02T23:30:00+09:00</published><updated>2018-06-02T23:30:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-06-02:/2018_06_02_build_performance_enhancement.html</id><summary type="html">&lt;p&gt;빌드 속도 올리기 팁&amp;nbsp;모음&lt;/p&gt;</summary><content type="html">&lt;p&gt;최근에 덩치가 큰 소프트웨어 작업을 진행하면서, 제대로 된 CI서버가 없어서 고단하던 참에, 때 마침 CI서버 구입 승인이 나면서 새롭게 구성했습니다.
대략적인 서버 사양은 다음과&amp;nbsp;같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;CPU&lt;/span&gt;: &lt;a href="https://ark.intel.com/products/126699/Intel-Core-i9-7980XE-Extreme-Edition-Processor-24_75M-Cache-up-to-4_20-GHz"&gt;Intel i9-7980 &lt;span class="caps"&gt;XE&lt;/span&gt;&lt;/a&gt; 18 Core 36 Thread&amp;nbsp;3.8GHz&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;RAM&lt;/span&gt;:&amp;nbsp;128Gb&lt;/li&gt;
&lt;li&gt;M/B: &lt;a href="https://www.gigabyte.com/Motherboard/X299-AORUS-Gaming-3-rev-10"&gt;Gigabyte X299 &lt;span class="caps"&gt;AORUS&lt;/span&gt; Gaming 3&amp;nbsp;Pro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;SSD&lt;/span&gt;: &lt;a href="https://ark.intel.com/products/125024/Intel-SSD-545s-Series-1_024TB-2_5in-SATA-6Gbs-3D2-TLC"&gt;Intel 545s&amp;nbsp;1Tb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;HDD&lt;/span&gt;: &lt;a href="https://www.hgst.com/products/hard-drives/nas-desktop-drive-kit"&gt;&lt;span class="caps"&gt;HGST&lt;/span&gt; &lt;span class="caps"&gt;HDN726040AL&lt;/span&gt;&amp;nbsp;4Tb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HP나 Dell 등과 같은 서버 벤더에서 구입하는 장비들은 가성비도 안 나오고, 게다가 굳이 서비스 받을 일도 없어서, PC부품 조립하는 것과 유사한 사양으로 뽑았습니다. 그리고 ubuntu 18.04 server 를 설치 후 작업 중인 소프트웨어 빌드(Android 8.1)를&amp;nbsp;수행해보았습니다.&lt;/p&gt;
&lt;p&gt;업무용 개인 Desktop &lt;span class="caps"&gt;PC&lt;/span&gt;(i7-7700k, 64Gb)에서 &lt;strong&gt;2시간 반&lt;/strong&gt; 가량 걸리던 작업이 &lt;strong&gt;1시간&lt;/strong&gt; 가량으로 줄어들었습니다만 만족할만한 수준은 되지&amp;nbsp;않았습니다.&lt;/p&gt;
&lt;p&gt;그래서 고려해야 할 사항을 나누어서 tuning을&amp;nbsp;해보았습니다.&lt;/p&gt;
&lt;h2&gt;cpu&amp;nbsp;governor&lt;/h2&gt;
&lt;p&gt;최근 intel cpu들은 &lt;a href="https://www.kernel.org/doc/Documentation/cpu-freq/intel-pstate.txt"&gt;작업 유무에 따라 자동으로 clock이 조정&lt;/a&gt;되는데 기본 값으로는 어떻게든 전원을 적게 사용하게 되어 있어서 기본 성능이 충분히 나오지 않습니다.
&lt;a href="https://www.archlinux.org/groups/x86_64/linux-tools/"&gt;linux-tools 패키지&lt;/a&gt;에 포함된 &lt;a href="https://wiki.archlinux.org/index.php/CPU_frequency_scaling#Scaling_governors"&gt;cpupower 라는 도구를 이용&lt;/a&gt;해 부팅할 때 cpu 성능을 되도록이면 잘 나올 수 있도록&amp;nbsp;조정했습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo cpupower frequency-set -g performance
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;disk&amp;nbsp;layout&lt;/h2&gt;
&lt;p&gt;빌드 할 때 사용할 disk는 다음과 같이 특성에 나누어서 &lt;a href="2018_04_18_using_bcache.html"&gt;bcache&lt;/a&gt; 및 zram을&amp;nbsp;활용했습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/dev/bcache0 :&amp;nbsp;/srv/workspace&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;빌드 할 때 필요한 소스를 내려받는 위치입니다. 수시로 gerrit서버의 자잘한 변경 사항을 checkout 하면서 write작업이 되어야 하기 때문에 writeback cache mode를 사용하도록&amp;nbsp;했습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/dev/bcache1 :&amp;nbsp;/srv/storage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;빌드 할 때 필요한 소스의 git object를 받아두는 위치입니다. 하루에 1번씩 밤에 gerrit서버의 전체 내용을 sync 합니다. 하루에 1번만 야간에 write작업이 이루어지기 때문에 write 속도는 빠르지 않아도 되어서, writethrough cache mode를&amp;nbsp;사용합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/dev/zram0 :&amp;nbsp;/srv/build&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;빌드 할 때 생성되는 object 파일을 보관하는 위치입니다. 여간하면 tmpfs를 이용하려고 했는데, android 프로젝트에서 생성하는 object 및 binary 크기가 130Gb에 육박해서 시스템의 메모리에 한꺼번에 적재가 되지 않습니다. 따라서 압축 기법을 이용하는 zram을 이용해서 물리적인 크기보다 훨씬 많은 데이터가 들어가게&amp;nbsp;구성했습니다.&lt;/p&gt;
&lt;h2&gt;repo init &amp;amp;&amp;amp;&amp;nbsp;sync&lt;/h2&gt;
&lt;p&gt;위에서 구성한 disk layout을 활용할 수 있도록 git-repo 를 이용해 소스 다운 받을 수 있도록&amp;nbsp;했습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;cd&lt;/span&gt; /src/workspace/Android
$ repo init -u http://gerrit.local/manifests &lt;span class="se"&gt;\&lt;/span&gt;
    --reference&lt;span class="o"&gt;=&lt;/span&gt;/srv/storage/gerrit-mirror
$ repo sync -j48 -c --no-tags
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;repo init 시 &lt;a href="2017_01_24_repo_mirror.html"&gt;&amp;#8212;reference 옵션을 이용하면 지정한 위치의 repository에 포함된 git object를 사용&lt;/a&gt;할 수 있으므로 처음 repo 를 구성하더라도 빠른 시간 내에 작업이&amp;nbsp;완료됩니다.&lt;/p&gt;
&lt;h2&gt;android clean&amp;nbsp;build&lt;/h2&gt;
&lt;p&gt;소스를 구성한 후, 빌드 할 때 다음과 같은 옵션을&amp;nbsp;사용합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;USE_CCACHE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
$ make -j48 droid &lt;span class="nv"&gt;OUT_DIR_COMMON_BASE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/srv/build dist
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;ccache를 이용해서 빌드 시간을 줄이는 것은 꽤 알려진 방법입니다. 이외에 안드로이드에서 빌드 할 때 OUT_DIR_COMMON_BASE 옵션을 주면 지정된 디렉토리 아래에 object 및 binary가 생성됩니다. 디렉토리 위치를 zram이 마운트 된 위치를 주게 해서, write속도에 이득을 얻으면서, 또한 flash write 회수를 줄여서 장비의 수명을 늘일 수 있게&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;그리고 dist 옵션을 사용하면 실제 단말에 필요한 파일만 out/dist 디렉토리에 모이게&amp;nbsp;됩니다.&lt;/p&gt;
&lt;h2&gt;incremental&amp;nbsp;build&lt;/h2&gt;
&lt;p&gt;풀 빌드가 끝난 뒤 이전 빌드의 오브젝트를 재활용해서 빌드 시간을 줄일 수 있습니다. 하지만 build target 설정이 달라지면 (ex: x86 -&amp;gt; arm) 기존의 바이너리가 대부분 재사용이 불가능합니다. 또한 ramdisk의 크기는 한정되어 있어서 build target별로 보관이&amp;nbsp;불가능합니다.&lt;/p&gt;
&lt;p&gt;그렇다고 build 결과물을 빌드할 때마다 복사하는 것은 빌드 시간보다 더 오래 걸리는 작업입니다. (build 결과물 130Gb 옮기는데 대략 10분&amp;nbsp;걸림)&lt;/p&gt;
&lt;p&gt;그래서 다음과 같은 빌드 전략을&amp;nbsp;세웠습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nightly build 는 항상 clean build&lt;ul&gt;
&lt;li&gt;clean build가 끝나면 /dev/bcache0 : /srv/workspace 디렉토리 아래의 지정된 위치에&amp;nbsp;복사&lt;/li&gt;
&lt;li&gt;nightly build 완료 이후, 추가 작업의 경우에는 빌드 서버의 이용자가 없을 것이기 때문에, 작업 시간이 오래 걸려도 상관이&amp;nbsp;없습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;incremental build 할 때는 nightly build 에서 빌드한 후 /srv/workspace 디렉토리로 옮겼던 작업 결과를 overlayfs 를 이용해 재활용&lt;ul&gt;
&lt;li&gt;리눅스의 &lt;a href="https://wiki.archlinux.org/index.php/Overlay_filesystem"&gt;overlayfs는 여러 개의 디렉토리를 엮어서 하나의 디렉토리처럼 표현&lt;/a&gt;해주며, &lt;a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/"&gt;docker에서 파일시스템 스냅샷 구현&lt;/a&gt;등에&amp;nbsp;이용됩니다.&lt;/li&gt;
&lt;li&gt;nightly build의 결과를 스냅샷으로 이용하고, 변경된 부분만 zram에 저장되게&amp;nbsp;합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이러한 최적화를 수행한 후 clean build는 기존의 &lt;strong&gt;1시간&lt;/strong&gt;에서 &lt;strong&gt;14분&lt;/strong&gt;으로 줄어 들었고, incremental build는 &lt;strong&gt;3분&lt;/strong&gt;만에 완료할 수 있게&amp;nbsp;되었습니다.&lt;/p&gt;</content><category term="software"></category><category term="continuous integration"></category><category term="performance"></category><category term="linux"></category></entry><entry><title>python 용 gerrit rest api binding</title><link href="http://ganadist.github.io/2018_05_20_pygerrit.html" rel="alternate"></link><published>2018-05-20T19:26:00+09:00</published><updated>2018-05-20T19:26:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-05-20:/2018_05_20_pygerrit.html</id><summary type="html">&lt;p&gt;gerrit rest api binding for&amp;nbsp;python&lt;/p&gt;</summary><content type="html">&lt;p&gt;회사에서 운영하던 고대의 &lt;a href="https://www.gerritcodereview.com/"&gt;gerrit 서비스&lt;/a&gt;를 새로운 기계로 이전하기 위해, 2주동안 신나게(?) &lt;a href="https://gerrit-review.googlesource.com/Documentation/cmd-index.html"&gt;ssh 스크립팅&lt;/a&gt;과 &lt;a href="https://gerrit.googlesource.com/plugins/importer/+/stable-2.15/src/main/resources/Documentation/about.md"&gt;importer plugin 을 이용&lt;/a&gt;해 겨우겨우&amp;nbsp;완료했습니다.&lt;/p&gt;
&lt;p&gt;결국 이전은 완료했건만, ssh 스크립팅은 확장성이 부족해서 재사용이 거의 불가능해 보이길래, 제대로된 gerrit api wrapper 를 찾아봤는데 그나마 멀쩡하게 생긴 넘이 sony 개발자가 만든 &lt;a href="https://github.com/dpursehouse/pygerrit2"&gt;pygerrit2 라는 물건&lt;/a&gt;이&amp;nbsp;보이네요.&lt;/p&gt;
&lt;p&gt;대략 코드를 살펴봤는데, 그렇게 길지는 않지만.. 그닥 python 개발자를 만족시키기에는 2% 부족해 보여서 결국 &lt;a href="https://www.lesstif.com/pages/viewpage.action?pageId=29590364"&gt;야크털깍기 시작&lt;/a&gt;..(..)&lt;/p&gt;
&lt;p&gt;해서 &lt;a href="https://github.com/ganadist/pygerrit"&gt;결과물&lt;/a&gt;이&amp;nbsp;나왔습니다.&lt;/p&gt;
&lt;p&gt;나름 대로의 바램을 &lt;a href="https://github.com/ganadist/pygerrit/blob/master/gerrit.py#L29"&gt;Feature에 정리&lt;/a&gt;하긴 했는데 계속 유지할 수 있을지는&amp;nbsp;미지수..(..)&lt;/p&gt;</content><category term="gerrit"></category><category term="python"></category><category term="rest"></category><category term="misc"></category><category term="opensource"></category></entry><entry><title>bcache 사용하기</title><link href="http://ganadist.github.io/2018_04_18_using_bcache.html" rel="alternate"></link><published>2018-04-18T15:04:00+09:00</published><updated>2018-04-18T15:04:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2018-04-18:/2018_04_18_using_bcache.html</id><summary type="html">&lt;p&gt;linux bcache를 이용해 sshd&amp;nbsp;만들기&lt;/p&gt;</summary><content type="html">&lt;p&gt;bcache 는 ssd와 hdd를 조합해서 &lt;a href="https://en.wikipedia.org/wiki/Hybrid_drive"&gt;sshd(hybrid drive)&lt;/a&gt;를 소프트웨어 적으로 구현하는 리눅스 커널의&amp;nbsp;기능입니다.&lt;/p&gt;
&lt;p&gt;일반적으로 ssd는 hdd보다 전송 속도 및 반응 속도가 빨라서 입출력이 많은 작업에 사용하기 좋지만, 가격이 비싸기 때문에 대용량의 데이터를 보관하는데 적합하지 않습니다. 하지만 빠른 반응속도를 가진 용량 작은 ssd(Intel Optane Memory등)와 적당한 가격의 큰 hdd를 bcache로 엮어주면 가성비가 괜찮은 sshd를 임의로 만들 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;p&gt;먼저 bcache를 구성하려면 데이터가 비어있는 ssd 파티션과 마찬가지로 데이터가 비어있는 hdd 파티션이&amp;nbsp;필요합니다.&lt;/p&gt;
&lt;p&gt;먼저 ssd 파티션을 bcache의 cache 장치로&amp;nbsp;등록합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo make-bcache -C --block &lt;span class="m"&gt;512&lt;/span&gt; --bucket 2M --wipe-bcache /dev/nvme0n1p3
UUID:            29373e97-cb10-4474-8ab2-2d99917da727
Set UUID:        7701c988-810e-4603-be15-a122c670975e
version:         &lt;span class="m"&gt;0&lt;/span&gt;
nbuckets:        &lt;span class="m"&gt;141280&lt;/span&gt;
block_size:      &lt;span class="m"&gt;1&lt;/span&gt;
bucket_size:     &lt;span class="m"&gt;4096&lt;/span&gt;
nr_in_set:       &lt;span class="m"&gt;1&lt;/span&gt;
nr_this_dev:     &lt;span class="m"&gt;0&lt;/span&gt;
first_bucket:    &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&amp;#8212;block 옵션은 연동할 hdd의 블럭단위크기로 설정하고, &amp;#8212;bucket 옵션은 ssd의 작업단위크기로 설정하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;단 &amp;#8212;bucket 옵션의 크기를 너무 크게 주면 등록이 되지 않기 때문에 오류가 발생하면 dmesg 명령으로 커널 메세지를 확인하시기&amp;nbsp;바랍니다.&lt;/p&gt;
&lt;p&gt;위와 같이 cache 장치로 등록하면 &amp;#8220;Set &lt;span class="caps"&gt;UUID&lt;/span&gt;&amp;#8221;를 주의깊게 기억하고 있다가 hdd를 등록할 때 사용하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;이미 등록된 ssd의 set uuid는 다음과 같이 확인해볼 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls -l /sys/fs/bcache
drwxr-xr-x &lt;span class="m"&gt;7&lt;/span&gt; root root    &lt;span class="m"&gt;0&lt;/span&gt;  4월 &lt;span class="m"&gt;18&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt;:34 7701c988-810e-4603-be15-a122c670975e
--w------- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;4096&lt;/span&gt;  4월 &lt;span class="m"&gt;18&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:36 register
--w------- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;4096&lt;/span&gt;  4월 &lt;span class="m"&gt;18&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:36 register_quiet
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;또는 다음 명령의 출력 결과 중 cset.uuid 를 확인해도&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;bcache&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;nvme0n1p3&lt;/span&gt;
&lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;           &lt;span class="n"&gt;ok&lt;/span&gt;
&lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;first_sector&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csum&lt;/span&gt;            &lt;span class="mi"&gt;268&lt;/span&gt;&lt;span class="n"&gt;D099BA966DCC6&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;         &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;           &lt;span class="mf"&gt;29373e97&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cb10&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4474&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="n"&gt;ab2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="n"&gt;d99917da727&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sectors_per_block&lt;/span&gt;     &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sectors_per_bucket&lt;/span&gt;    &lt;span class="mi"&gt;8192&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;first_sector&lt;/span&gt;    &lt;span class="mi"&gt;8192&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache_sectors&lt;/span&gt;   &lt;span class="mi"&gt;578674688&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;total_sectors&lt;/span&gt;   &lt;span class="mi"&gt;578682880&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ordered&lt;/span&gt;    &lt;span class="n"&gt;yes&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;discard&lt;/span&gt;    &lt;span class="n"&gt;no&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;        &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replacement&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;lru&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;cset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;          &lt;span class="mi"&gt;7701&lt;/span&gt;&lt;span class="n"&gt;c988&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;810e-4603&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;be15&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;a122c670975e&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;ssd가 구성되면, backing partition으로 사용될 hdd 를 초기화 합니다. 다음 옵션중 &amp;#8212;cset-uuid 의 인자는 위에서 확인했던 set uuid를 입력하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CSET_UUID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;7701c988-810e-4603-be15-a122c670975e
$ sudo make-bcache -B  --writeback --cset-uuid &lt;span class="nv"&gt;$CSET_UUID&lt;/span&gt; /dev/sdb2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;이렇게 명령을 수행하면 bcache0 장치가 등록되는데, 커널 메세지로 확인이&amp;nbsp;가능합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bcache&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;register_cache&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="n"&gt;registered&lt;/span&gt; &lt;span class="n"&gt;cache&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt; &lt;span class="n"&gt;nvme0n1p3&lt;/span&gt;
&lt;span class="n"&gt;bcache&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;register_bdev&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="n"&gt;registered&lt;/span&gt; &lt;span class="n"&gt;backing&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt; &lt;span class="n"&gt;sdb2&lt;/span&gt;
&lt;span class="n"&gt;bcache&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bch_cached_dev_attach&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="n"&gt;Caching&lt;/span&gt; &lt;span class="n"&gt;sdb2&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;bcache0&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="kd"&gt;set&lt;/span&gt; &lt;span class="mi"&gt;7701&lt;/span&gt;&lt;span class="n"&gt;c988&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;810&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4603&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;be15&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;a122c670975e&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;이렇게 생성된 bcache 장치에 파일시스템을 구성 후 mount 하고 사용하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo mkfs.ext4 -L BUILD_OUT /dev/bcache0
$ sudo mount /dev/bcache0 /srv/build/out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;그리고 용도에 따라서 cache mode를 변경할 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;writeback : write 에 대해 cache 가 됩니다. 시스템이 비정상적으로 종료되거나, 갑작스런 전원공급 중단이 발생할 경우 데이터가 유실될 가능성이 있습니다만, 빠른 write속도가&amp;nbsp;제공됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;writethrough: ssd와 hdd에 동시에 write를&amp;nbsp;합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;writearound: write cache가 동작하지&amp;nbsp;않습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;아래 2가지 모드에서는 writeback보다 write속도가 떨어지지만, 그만큼 안정성은 올라갑니다. 저장장치의 용도에 따라 적합한 cache mode를 선택해서 사용하면&amp;nbsp;됩니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat /sys/block/bcache0/bcache/cache_mode
writethrough writeback &lt;span class="o"&gt;[&lt;/span&gt;writearound&lt;span class="o"&gt;]&lt;/span&gt; none
$ &lt;span class="nb"&gt;echo&lt;/span&gt; writeback &lt;span class="p"&gt;|&lt;/span&gt; sudo tee /sys/block/bcache0/bcache/cache_mode
writeback
$ cat /sys/block/bcache0/bcache/cache_mode
writethrough &lt;span class="o"&gt;[&lt;/span&gt;writeback&lt;span class="o"&gt;]&lt;/span&gt; writearound none
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;참고:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bcache.evilpiepirate.org/"&gt;공식&amp;nbsp;홈페이지&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torvalds/linux/blob/master/Documentation/bcache.txt"&gt;커널&amp;nbsp;문서&lt;/a&gt;    &lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.archlinux.org/index.php/Bcache"&gt;Arch Linux&amp;nbsp;문서&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.ubuntu.com/ServerTeam/Bcache"&gt;Ubuntu&amp;nbsp;문서&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="linux"></category><category term="performance"></category><category term="ssd"></category><category term="hdd"></category></entry><entry><title>TCP access control in Android Frameworks</title><link href="http://ganadist.github.io/2017_08_16_tcp_on_android.html" rel="alternate"></link><published>2017-08-16T19:00:00+09:00</published><updated>2017-08-16T19:00:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2017-08-16:/2017_08_16_tcp_on_android.html</id><summary type="html">&lt;p&gt;Android Framework에서 소켓권한 제어&amp;nbsp;방법&lt;/p&gt;</summary><content type="html">&lt;p&gt;2년 전에 완전정복 했었다고 믿었건만, 지나가면 새까맣게 잊어먹는 습성때문에 기록으로&amp;nbsp;남깁니다.&lt;/p&gt;
&lt;h1&gt;Android 1.0 ~ Android&amp;nbsp;4.4&lt;/h1&gt;
&lt;p&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; 소켓을 생성할 때는 리눅스 커널의 &lt;a href="http://man7.org/linux/man-pages/man2/socket.2.html"&gt;socket 이라는 시스템콜&lt;/a&gt;을 이용해 생성하게 되어 있는데,  android의 리눅스 커널에는 특정 그룹(AID_INET, AID_NET_RAW)이나 특정 capability(CAP_NET_RAW)를 가지고 있는 process에 대해서만 socket 시스템 콜을 호출할 수 있는 &lt;a href="https://android.googlesource.com/kernel/common/+/fd64bbf28e28526f608df0061175829338ee94cc%5E%21/"&gt;변경사항을 포함&lt;/a&gt;하고&amp;nbsp;있습니다.&lt;/p&gt;
&lt;p&gt;그리고 앱에 &lt;a href="https://developer.android.com/reference/android/Manifest.permission.html#INTERNET"&gt;&lt;span class="caps"&gt;INTERNET&lt;/span&gt; 이라는 퍼미션&lt;/a&gt;을 포함하고 있으면, 해당 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/lollipop-mr1-release/data/etc/platform.xml#53"&gt;앱의 group에 inet 을 포함&lt;/a&gt;시켜줍니다.&lt;/p&gt;
&lt;p&gt;따라서 해당 퍼미션을 가지고 있지 않은 daemon이나 앱에서는 socket을 생성할 때 &lt;span class="caps"&gt;EACCESS&lt;/span&gt;(퍼미션 없음) 오류를 발생하게&amp;nbsp;됩니다.&lt;/p&gt;
&lt;h1&gt;Android 5.0&amp;nbsp;~&lt;/h1&gt;
&lt;p&gt;새로운 &lt;a href="https://developer.android.com/about/versions/android-5.0.html#Multinetwork"&gt;connectivity api&lt;/a&gt; 로 인해 socket 퍼미션을 동적으로 관리하기 위해서 &lt;a href="https://android.googlesource.com/platform/system/netd/+/android-7.1.1_r50"&gt;netd 라는 daemon이 완전히 개비&lt;/a&gt;되었습니다. (&lt;a href="https://android.googlesource.com/platform/system/netd/+/kitkat-dev"&gt;킷캣 이전에도 netd는 존재&lt;/a&gt;했지만 테터링이나 vpn등의 제한된 기능만&amp;nbsp;제공했습니다.)&lt;/p&gt;
&lt;p&gt;c 라이브러리(bionic)의 socket 관련 시스템 콜(&lt;a href="https://android.googlesource.com/platform/bionic/+/android-7.1.1_r50/libc/bionic/socket.cpp"&gt;socket&lt;/a&gt;, &lt;a href="https://android.googlesource.com/platform/bionic/+/android-7.1.1_r50/libc/bionic/accept4.cpp"&gt;accept4&lt;/a&gt;, &lt;a href="https://android.googlesource.com/platform/bionic/+/android-7.1.1_r50/libc/bionic/connect.cpp"&gt;connect&lt;/a&gt;) 래퍼는 직접 커널에서 제공되는 시스템콜을 호출하지 않고, &lt;a href="https://android.googlesource.com/platform/bionic/+/android-7.1.1_r50/libc/bionic/NetdClient.cpp"&gt;netd 에서 제공되는 래퍼 함수를 호출&lt;/a&gt;합니다.&lt;/p&gt;
&lt;p&gt;그리고 각 socket관련 시스템 콜을 호출할 때는 &lt;a href="https://android.googlesource.com/platform/system/netd/+/android-7.1.1_r50/server/FwmarkServer.cpp#207"&gt;각 socket에 대해 fwmark(Firewall Mark)라는 것을 설정&lt;/a&gt;하고, 라우팅 테이블에서 fwmark를 이용해 해당 패킷을 실제로 교환할 지&amp;nbsp;결정합니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mako:/ # ip rule
0:      from all lookup local
10000:  from all fwmark 0xc0000/0xd0000 lookup legacy_system
10500:  from all oif dummy0 uidrange 0-0 lookup dummy0
10500:  from all oif wlan0 uidrange 0-0 lookup wlan0
13000:  from all fwmark 0x10063/0x1ffff lookup local_network
13000:  from all fwmark 0x10064/0x1ffff lookup wlan0
14000:  from all oif dummy0 lookup dummy0
14000:  from all oif wlan0 lookup wlan0
15000:  from all fwmark 0x0/0x10000 lookup legacy_system
16000:  from all fwmark 0x0/0x10000 lookup legacy_network
17000:  from all fwmark 0x0/0x10000 lookup local_network
19000:  from all fwmark 0x64/0x1ffff lookup wlan0
22000:  from all fwmark 0x0/0xffff lookup wlan0
23000:  from all fwmark 0x0/0xffff uidrange 0-0 lookup main
32000:  from all unreachable
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;따라서 퍼미션을 가지지 않는 데몬이나 앱이 tcp연결을 시도하면, 킷캣 미만처럼 EACCESS오류가 발생하는 것이 아니라,  송신용 소켓일 경우에는  &lt;span class="caps"&gt;ENETUNREACH&lt;/span&gt;(Network is unreachable)이 발생하며, 수신용 소켓일 경우에는 라우팅이 되지 않아 아예 패킷 수신이 되지&amp;nbsp;않습니다.&lt;/p&gt;
&lt;p&gt;또한 네트워크 인터페이스가 netd 및 connectivity service에 등록되지 않은 상태이면, 마찬가지로 라우팅 테이블에서 해당 패킷을 처리하지 않게 되므로, 패킷 송수신이 불가능한 상태가&amp;nbsp;됩니다.&lt;/p&gt;
&lt;p&gt;임의로 네트워크 인터페이스를 netd에 등록하려면 다음 명령을 미리 실행해&amp;nbsp;놓습니다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mako:/ # ndc network create 100
mako:/ # ndc network default set 100
mako:/ # ndc network interface add 100 eth0
mako:/ # dumpsys netd

  NetworkController
    Default network: 100

    Networks:
      51 DUMMY dummy0
        No DNS servers defined
        No search domains defined

      99 LOCAL
        No DNS servers defined
        No search domains defined

      100 PHYSICAL eth0,wlan0
        Required permission: NONE
        DNS servers: # IP (total, successes, errors, timeouts, internal errors, RTT avg, last sample)
          168.126.63.1 (38, 38, 0, 0, 0, 47ms, 562s)
          168.126.63.2 &amp;lt;no data&amp;gt;
        No search domains defined
        DNS parameters: sample validity = 1800s, success threshold = 25%, samples (min, max) = (8, 64)
&lt;/pre&gt;&lt;/div&gt;</content><category term="android"></category><category term="network"></category></entry><entry><title>repo mirror 를 이용해 git 저장용량을 절약하기</title><link href="http://ganadist.github.io/2017_01_24_repo_mirror.html" rel="alternate"></link><published>2017-01-24T19:00:00+09:00</published><updated>2017-01-24T19:00:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2017-01-24:/2017_01_24_repo_mirror.html</id><summary type="html">&lt;p&gt;repo init의 &amp;#8212;reference 옵션&amp;nbsp;사용하기&lt;/p&gt;</summary><content type="html">&lt;p&gt;회사에서 하는 작업의 특성상, 대 여섯이상의 안드로이드 버젼 소스를 동시에 다루는 때가 많다. 하지만 그때마다 안드로이드 버젼의 소스를 그때그때 구성하는 것은 무지막지한 자원&amp;nbsp;낭비다.&lt;/p&gt;
&lt;p&gt;현재 안드로이드 소스에 등록(manifest.xml)된 git repo 개수는 529개, 소스 용량은 대략 6G 가량 된다. 이걸 필요할 때마다 &lt;a href="https://android.googlesource.com/"&gt;구글 서버&lt;/a&gt;로 부터 소스를 전송받아 구성하는 것은 여러모로 불합리해보여서 로컬네트워크에 &lt;a href="https://android.googlesource.com/mirror/manifest/"&gt;미러서버를 구성&lt;/a&gt;해보기도 했으나, 네트워크가 여전히 병목인 것은 변함이 없었다. 그래서 아예 PC에다가 mirror를 마련하고 사용하기도&amp;nbsp;했다.&lt;/p&gt;
&lt;p&gt;하지만 PC에다가 mirror를 마련하니 소스를 구성하는데 필요한 시간은 조금 줄어들었지만, 미러주기 사이에 달라진 변경사항에 대해서는 바로바로 확인이 불가능한 단점이 발생하였다. 게다가 더 큰 문제는 소스와 더불어 git 저장소까지 복제가 되다보니 PC의 저장장소 부족현상에 허덕이게 되었다. 그렇게 고민이 깊어가던&amp;nbsp;중..(..)&lt;/p&gt;
&lt;p&gt;어느날 repo 명령어 도움말을 보다가 repo init 명령에 &lt;a href="https://gerrit.googlesource.com/git-repo/+/8844338%5E%21/"&gt;&amp;#8212;reference 옵션&lt;/a&gt;이 추가된 것을 발견. 구현은 아주&amp;nbsp;간단하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;repo init를 수행할 때 &lt;a href="https://gerrit.googlesource.com/git-repo/+/v1.12.37/subcmds/init.py#209"&gt;.repo/manifests 의 git config에 repo.reference 값을 지정한 디렉토리로&amp;nbsp;설정&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;repo sync를 최초로 수행할 때, &lt;a href="https://gerrit.googlesource.com/git-repo/+/v1.12.37/project.py#2287"&gt;각 repo project에 대한 저장소를 생성하면서 .git/object/info/alternatives 를 .repo/manifests 에 등록했던 repo.reference값으로&amp;nbsp;채움&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;git 문서를 확인해보니 .git/object/info/alternatives 파일을 이용하면, &lt;a href="https://git-scm.com/docs/gitrepository-layout#gitrepository-layout-objects"&gt;git의 object를 복사하지 않고 지정된 디렉토리에서 찾는다&lt;/a&gt;고&amp;nbsp;한다.&lt;/p&gt;
&lt;p&gt;이 방식으로 repo init 명령을 이용해 안드로이드 소스 작업환경을 구성하면, git object를 복사할 필요가 없어져서 환경구성에 필요한 디스크공간도 절약과 함께, 소요되는 시간도&amp;nbsp;짧아진다.&lt;/p&gt;
&lt;p&gt;뱀발: &amp;#8212;reference 옵션을 이용할 때 디렉토리 위치를 절대경로로 지정해야 했지만, &lt;a href="https://gerrit-review.googlesource.com/#/c/95310/"&gt;최근 수정에 의해 상대경로도 정상적으로 동작&lt;/a&gt;하도록&amp;nbsp;변경되었다.&lt;/p&gt;</content><category term="android"></category><category term="gerrit"></category><category term="git"></category><category term="repo"></category></entry><entry><title>어플리케이션 Crash 처리하기</title><link href="http://ganadist.github.io/2016_06_22_handle_crash.html" rel="alternate"></link><published>2016-06-22T19:00:00+09:00</published><updated>2016-06-22T19:00:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2016-06-22:/2016_06_22_handle_crash.html</id><summary type="html">&lt;p&gt;리눅스에서 어플리케이션 crash가 처리되는&amp;nbsp;방법&lt;/p&gt;</summary><content type="html">&lt;p&gt;최근 리눅스 배포판들은 c 런타임에서 어플리케이션의 버그나 이상동작으로 인해 중단될 때, crash report 설비를 이용해서 어떤 어플리케이션이 무슨 이유로 인해 중단되었는지 확인할 수 있게 해준다.
crash report 처리기들이 어떠한 방식으로 데이터를 구동되는지 대충 살펴보도록&amp;nbsp;하자.&lt;/p&gt;
&lt;h1&gt;&lt;a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/Documentation/sysctl/kernel.txt?h=v4.4#n182"&gt;/proc/sys/kernel/core_pattern&lt;/a&gt;&amp;nbsp;이용하기&lt;/h1&gt;
&lt;p&gt;core_pattern 은 프로그램이 오류가 발생했을 때 생성할 메모리 덤프파일의 이름 형식을 지정할 때 사용한다. 하지만 &lt;a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/fs/coredump.c?h=v4.4#n561"&gt;파일이름을 등록할 때 맨 앞에 ‘|’ 로 시작&lt;/a&gt;하면 저장할 파일이름 대신 ‘|’ 뒤를 실행파일로 취급하고 표준입력으로 메모리 내용을 건네준다.
이를 이용해서 동작하는 프로그램은 다음과&amp;nbsp;같다.&lt;/p&gt;
&lt;h2&gt;systemd: &lt;a href="https://www.freedesktop.org/software/systemd/man/systemd-coredump.html"&gt;systemd-coredump&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;systemd를 사용하는 시스템에서는 &lt;a href="https://github.com/systemd/systemd/blob/master/sysctl.d/50-coredump.conf.in"&gt;sysctl을 이용해 systemd-coredump를 core_pattern에 등록&lt;/a&gt;한다. 그리고 오류가 발생하면, 해당 프로세스의 스택은 물론, systemd 에 의존적인 정보까지 추가해서 기록한다.
이렇게 기록된 정보는 아래의 명령을 이용해서 확인할 수&amp;nbsp;있다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ coredumpctl info
           PID: &lt;span class="m"&gt;1849&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;nautilus&lt;span class="o"&gt;)&lt;/span&gt;
           UID: &lt;span class="m"&gt;1000&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;ganadist&lt;span class="o"&gt;)&lt;/span&gt;
           GID: &lt;span class="m"&gt;100&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;users&lt;span class="o"&gt;)&lt;/span&gt;
        Signal: &lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;ABRT&lt;span class="o"&gt;)&lt;/span&gt;
     Timestamp: 일 &lt;span class="m"&gt;2016&lt;/span&gt;-04-24 &lt;span class="m"&gt;16&lt;/span&gt;:07:38 KST &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; months &lt;span class="m"&gt;27&lt;/span&gt; days ago&lt;span class="o"&gt;)&lt;/span&gt;
  Command Line: nautilus -n
    Executable: /usr/bin/nautilus
 Control Group: /user.slice/user-1000.slice/session-c4.scope
          Unit: session-c4.scope
         Slice: user-1000.slice
       Session: c4
     Owner UID: &lt;span class="m"&gt;1000&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;ganadist&lt;span class="o"&gt;)&lt;/span&gt;
       Boot ID: f83aada45fed429299c962af79ea736d
    Machine ID: 3cfa38b6a39d4190be174d821f3d8e30
      Hostname: ganadist
       Message: Process &lt;span class="m"&gt;1849&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;nautilus&lt;span class="o"&gt;)&lt;/span&gt; of user &lt;span class="m"&gt;1000&lt;/span&gt; dumped core.

                Stack trace of thread &lt;span class="m"&gt;1849&lt;/span&gt;:
                &lt;span class="c1"&gt;#0  0x00007fe516a212a8 raise (libc.so.6)&lt;/span&gt;
                &lt;span class="c1"&gt;#1  0x00007fe516a2272a abort (libc.so.6)&lt;/span&gt;
                &lt;span class="c1"&gt;#2  0x00007fe51789eb25 g_assertion_message (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#3  0x00007fe51789ebba g_assertion_message_expr (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#4  0x0000000000488a01 n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#5  0x000000000048bba7 n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#6  0x0000000000435288 n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#7  0x0000000000436333 n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#8  0x00007fe517b51518 g_cclosure_marshal_VOID__ENUMv (libgobject-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#9  0x00007fe517b4f1d4 n/a (libgobject-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#10 0x00007fe517b699d6 g_signal_emit_valist (libgobject-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#11 0x00007fe517b6a0bf g_signal_emit (libgobject-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#12 0x0000000000444fac n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#13 0x000000000044526f n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#14 0x00007fe517879823 n/a (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#15 0x00007fe517878dba g_main_context_dispatch (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#16 0x00007fe517879160 n/a (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#17 0x00007fe51787920c g_main_context_iteration (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#18 0x00007fe517e3eafd g_application_run (libgio-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#19 0x00000000004294e7 n/a (nautilus)&lt;/span&gt;
                &lt;span class="c1"&gt;#20 0x00007fe516a0e710 __libc_start_main (libc.so.6)&lt;/span&gt;
                &lt;span class="c1"&gt;#21 0x0000000000429549 n/a (nautilus)&lt;/span&gt;

                Stack trace of thread &lt;span class="m"&gt;1933&lt;/span&gt;:
                &lt;span class="c1"&gt;#0  0x00007fe516ad17f9 syscall (libc.so.6)&lt;/span&gt;
                &lt;span class="c1"&gt;#1  0x00007fe5178bdafa g_cond_wait_until (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#2  0x00007fe51784d929 n/a (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#3  0x00007fe5178a02e6 n/a (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#4  0x00007fe51789f975 n/a (libglib-2.0.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#5  0x00007fe516d96424 start_thread (libpthread.so.0)&lt;/span&gt;
                &lt;span class="c1"&gt;#6  0x00007fe516ad5cbd __clone (libc.so.6)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;&lt;a href="https://wiki.ubuntu.com/Apport"&gt;Apport&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;우분투 리눅스에서는 apport 라고하는 crash report 도구가 존재하며, &lt;a href="http://bazaar.launchpad.net/~ubuntu-core-dev/ubuntu/xenial/apport/ubuntu/view/head:/etc/init.d/apport#L52"&gt;init 스크립트에서 core_pattern에 등록&lt;/a&gt;한다. 또한 apport에는 몇가지 추가동작을 하게 되는데 다음과&amp;nbsp;같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;오류 동작시 &lt;a href="http://bazaar.launchpad.net/~ubuntu-core-dev/ubuntu/xenial/apport/ubuntu/view/head:/bin/apport-bug#L57"&gt;실행환경을 분석&lt;/a&gt;하여, gnome, kde 또는 cli 에 해당하는 UI를&amp;nbsp;보여줌&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;c 런타임에서 발생하는 메모리 오류 이외에 여러가지 상황에 대한 오류분석이 추가되어&amp;nbsp;있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;python 해석기에서 예외가 발생할 때 처리할 수 있는 &lt;a href="http://bazaar.launchpad.net/~ubuntu-core-dev/ubuntu/xenial/apport/ubuntu/view/head:/apport_python_hook.py#L200"&gt;예외 처리기가 포함&lt;/a&gt;되어&amp;nbsp;있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://bazaar.launchpad.net/~ubuntu-core-dev/ubuntu/xenial/apport/ubuntu/view/head:/udev/50-apport.rules"&gt;intel wifi 드라이버에서 오류가 발생&lt;/a&gt;할 경우, &lt;a href="http://bazaar.launchpad.net/~ubuntu-core-dev/ubuntu/xenial/apport/ubuntu/view/head:/data/iwlwifi_error_dump"&gt;오류를 수집 분석&lt;/a&gt;한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;뭔가 자바쪽도 bootclasspath에 등록할 것 같은데 귀찮아서&amp;nbsp;못뒤벼보겠..(..)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그외 오류 패턴별로 우분투의 이슈추적시스템인 launchpad에 등록된 것과 일치하는 것을 뒤벼주는 것도 포함되어&amp;nbsp;있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;당연히 오류를 launchpad에 업로드 하는 기능도&amp;nbsp;있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;어쨌든 본인은 우분투를 사용하지 않는다&amp;#8230;&amp;nbsp;(먼산)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Android에서 Crash&amp;nbsp;처리하기&lt;/h1&gt;
&lt;h2&gt;c 런타임의 오류&amp;nbsp;처리&lt;/h2&gt;
&lt;p&gt;Android에서는 리눅스에서 제공하는 core_pattern 대신 &lt;a href="https://android.googlesource.com/platform/bionic/+/android-6.0.1_r46/linker/debugger.cpp#296"&gt;linker에서 어플리케이션을 실행할 때 signal handler를 등록&lt;/a&gt;한다.&lt;/p&gt;
&lt;p&gt;그리고 오류가 발생할 때 커널에서 보내는 여러가지 &lt;a href="https://android.googlesource.com/platform/bionic/+/android-6.0.1_r46/linker/debugger.cpp#257"&gt;signal(&lt;span class="caps"&gt;SIGABRT&lt;/span&gt;, &lt;span class="caps"&gt;SIGFPE&lt;/span&gt;, &lt;span class="caps"&gt;SIGSEGV&lt;/span&gt;, &lt;span class="caps"&gt;SIGBUS&lt;/span&gt;, &lt;span class="caps"&gt;SIGTRAP&lt;/span&gt;) 등을 받아서&lt;/a&gt; &lt;a href="https://android.googlesource.com/platform/bionic/+/android-6.0.1_r46/linker/debugger.cpp#206"&gt;debuggerd에게 처리해달라고 요청&lt;/a&gt;하게 되고, debuggerd는 요청한 프로세스에 대해 &lt;a href="https://android.googlesource.com/platform/system/core/+/android-6.0.1_r46/debuggerd/tombstone.cpp#783"&gt;tombstone 이라는 형식으로 프로세스의 스택에 대한 정보를 파일로 저장&lt;/a&gt;하게 된다. 그리고 이렇게 저장된 tombstone 형식의 파일은 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/server/BootReceiver.java#63"&gt;안드로이드가 다음 부팅&lt;/a&gt;될 때 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/server/BootReceiver.java#153"&gt;dropbox 라고 하는 android os의  로그 서비스 저장소&lt;/a&gt;로 옮겨지게&amp;nbsp;된다.&lt;/p&gt;
&lt;h2&gt;dalvik 런타임의 오류&amp;nbsp;처리&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/internal/os/RuntimeInit.java#256"&gt;Zygote 가 초기화&lt;/a&gt; 될 때 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/internal/os/RuntimeInit.java#89"&gt;ActivityManagerService 에서 crash를 처리&lt;/a&gt;할 수 있는 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/internal/os/RuntimeInit.java#64"&gt;기본 예외 처리기&lt;/a&gt;를 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/internal/os/RuntimeInit.java#109"&gt;등록&lt;/a&gt;하게&amp;nbsp;된다.&lt;/p&gt;
&lt;p&gt;ActivityManagerService에서는 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/services/core/java/com/android/server/am/ActivityManagerService.java#12127"&gt;dropbox에 crash 정보를 저장&lt;/a&gt;하고,  &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/android/app/ApplicationErrorReport.java#159"&gt;os 에 지정된 crash report 어플리케이션&lt;/a&gt;이 있으며, &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/services/core/java/com/android/server/am/AppErrorDialog.java#66"&gt;사용자가 해당 앱을 사용하겠다고 선택&lt;/a&gt;하면, &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/services/core/java/com/android/server/am/ActivityManagerService.java#12648"&gt;해당 앱을 이용해 오류정보를 전송&lt;/a&gt;하게&amp;nbsp;된다.&lt;/p&gt;
&lt;h2&gt;dropbox에 저장된 오류&amp;nbsp;확인하기&lt;/h2&gt;
&lt;p&gt;아래의 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/core/java/com/android/server/BootReceiver.java#157"&gt;SYSTEM_TOMBSTONE&lt;/a&gt; 옵션은 tombstone 에 대한 오류에 대해 조회하는 명령이며, app crash는 앱의 설치 위치에 따라 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/services/core/java/com/android/server/am/ActivityManagerService.java#12436"&gt;system_app&lt;/a&gt;_crash, 또는 &lt;a href="https://android.googlesource.com/platform/frameworks/base/+/android-6.0.1_r46/services/core/java/com/android/server/am/ActivityManagerService.java#12439"&gt;data_app&lt;/a&gt;_crash 등의 옵션으로 조회가&amp;nbsp;가능하다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ adb shell dumpsys dropbox --print SYSTEM_TOMBSTONE
Drop box contents: &lt;span class="m"&gt;634&lt;/span&gt; entries
Searching &lt;span class="k"&gt;for&lt;/span&gt;: &lt;span class="nv"&gt;SYSTEM_TOMBSTONE&lt;/span&gt;

&lt;span class="o"&gt;========================================&lt;/span&gt;
&lt;span class="m"&gt;2016&lt;/span&gt;-06-21 &lt;span class="m"&gt;18&lt;/span&gt;:21:15 SYSTEM_TOMBSTONE &lt;span class="o"&gt;(&lt;/span&gt;compressed text, &lt;span class="m"&gt;6361&lt;/span&gt; bytes&lt;span class="o"&gt;)&lt;/span&gt;
Build: google/hammerhead/hammerhead:6.0.1/MOB30M/2862625:user/release-keys
Hardware: hammerhead
Revision: &lt;span class="m"&gt;11&lt;/span&gt;
Bootloader: HHZ20f
Radio: unknown
Kernel: Linux version &lt;span class="m"&gt;3&lt;/span&gt;.4.0-g6a99a02 &lt;span class="o"&gt;(&lt;/span&gt;android-build@wpdt13.hot.corp.google.com&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;gcc version &lt;span class="m"&gt;4&lt;/span&gt;.8 &lt;span class="o"&gt;(&lt;/span&gt;GCC&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#1 SMP PREEMPT Wed Apr 20 00:08:32 UTC 2016&lt;/span&gt;

*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
Build fingerprint: &lt;span class="s1"&gt;&amp;#39;google/hammerhead/hammerhead:6.0.1/MOB30M/2862625:user/release-keys&amp;#39;&lt;/span&gt;
Revision: &lt;span class="s1"&gt;&amp;#39;11&amp;#39;&lt;/span&gt;
ABI: &lt;span class="s1"&gt;&amp;#39;arm&amp;#39;&lt;/span&gt;
pid: &lt;span class="m"&gt;224&lt;/span&gt;, tid: &lt;span class="m"&gt;224&lt;/span&gt;, name: mm-qcamera-daem  &amp;gt;&amp;gt;&amp;gt; /system/bin/mm-qcamera-daemon &lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;
signal &lt;span class="m"&gt;11&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;SIGSEGV&lt;span class="o"&gt;)&lt;/span&gt;, code &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;SEGV_MAPERR&lt;span class="o"&gt;)&lt;/span&gt;, fault addr 0x357b9a70
    r0 000000a8  r1 b48c1290  r2 &lt;span class="m"&gt;00800000&lt;/span&gt;  r3 b48c1299
    r4 b48c1298  r5 357b9a60  r6 b6b55300  r7 b48c1298
    r8 b48c0000  r9 000000a7  sl 000000a3  fp b48c1538
    ip &lt;span class="m"&gt;00000038&lt;/span&gt;  sp bedae540  lr b6d78920  pc b6d42128  cpsr 800f0030
    d0  2064656c69616620  d1  735f74696e695f73
    d2  &lt;span class="m"&gt;0000000000000073&lt;/span&gt;  d3  &lt;span class="m"&gt;0000000000000069&lt;/span&gt;
    d4  &lt;span class="m"&gt;0000000600000001&lt;/span&gt;  d5  c01e33f0c300a020
    d6  c11a644000000000  d7  c300bd20c300bd64
    d8  &lt;span class="m"&gt;0000000000000000&lt;/span&gt;  d9  &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
    d10 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;  d11 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
    d12 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;  d13 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
    d14 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;  d15 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
    d16 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;  d17 &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
    d18 3fe0000000000000  d19 3fe0000000000000
    d20 3fe0000000000000  d21 bfe0000000000000
    d22 4053bd6de0000000  d23 3fe0000000000000
    d24 4053dd6de0000000  d25 3ff30a3d70a3d70a
    d26 3ff6a0902de00d1b  d27 40a65cae7d566cf4
    d28 40b13c51eb851eb9  d29 406d038366516db1
    d30 40ad038366516db1  d31 4072d11eb851eb85
    scr &lt;span class="m"&gt;20000011&lt;/span&gt;

backtrace:
    &lt;span class="c1"&gt;#00 pc 0004b128  /system/lib/libc.so (arena_dalloc_bin_locked_impl.isra.27+299)&lt;/span&gt;
    &lt;span class="c1"&gt;#01 pc 0005c32f  /system/lib/libc.so (je_tcache_bin_flush_small+206)&lt;/span&gt;
    &lt;span class="c1"&gt;#02 pc 000553cb  /system/lib/libc.so (ifree+290)&lt;/span&gt;
    &lt;span class="c1"&gt;#03 pc 00058257  /system/lib/libc.so (je_free+374)&lt;/span&gt;
    &lt;span class="c1"&gt;#04 pc 000034d7  /system/vendor/lib/libmmcamera2_sensor_modules.so&lt;/span&gt;
    &lt;span class="c1"&gt;#05 pc 00005853  /system/vendor/lib/libmmcamera2_sensor_modules.so&lt;/span&gt;
    &lt;span class="c1"&gt;#06 pc 00007189  /system/vendor/lib/liboemcamera.so (mct_list_traverse+26)&lt;/span&gt;
    &lt;span class="c1"&gt;#07 pc 00004d55  /system/vendor/lib/liboemcamera.so (mct_pipeline_start_session+16)&lt;/span&gt;
    &lt;span class="c1"&gt;#08 pc 00002b3f  /system/vendor/lib/liboemcamera.so (mct_controller_new+50)&lt;/span&gt;
    &lt;span class="c1"&gt;#09 pc 000016b3  /system/bin/mm-qcamera-daemon&lt;/span&gt;
    &lt;span class="c1"&gt;#10 pc 00001205  /system/bin/mm-qcamera-daemon (main+520)&lt;/span&gt;
    &lt;span class="c1"&gt;#11 pc 00017359  /system/lib/libc.so (__libc_init+44)&lt;/span&gt;
    &lt;span class="c1"&gt;#12 pc 0000148c  /system/bin/mm-qcamera-daemon&lt;/span&gt;

stack:
         bedae500  bedae4e4  &lt;span class="o"&gt;[&lt;/span&gt;stack&lt;span class="o"&gt;]&lt;/span&gt;
         bedae504  bedae4e4  &lt;span class="o"&gt;[&lt;/span&gt;stack&lt;span class="o"&gt;]&lt;/span&gt;
         bedae508  b6680000
         bedae50c  b6d792f0
         bedae510  b6d792e0
         bedae514  &lt;span class="m"&gt;00100000&lt;/span&gt;
         bedae518  &lt;span class="m"&gt;00000000&lt;/span&gt;
         bedae51c  &lt;span class="m"&gt;00000002&lt;/span&gt;
         bedae520  b6b556f8  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae524  b6b55300  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae528  b48c1394  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae52c  b48c0000  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae530  b6b556f8  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae534  &lt;span class="m"&gt;00000000&lt;/span&gt;
         bedae538  &lt;span class="m"&gt;00000002&lt;/span&gt;
         bedae53c  b6d421f7  /system/lib/libc.so &lt;span class="o"&gt;(&lt;/span&gt;arena_dalloc_bin_locked_impl.isra.27+506&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;#00  bedae540  00000001&lt;/span&gt;
         bedae544  b6d7c0e8  /system/lib/libc++.so
         bedae548  b48fa048  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae54c  b6b02048  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae550  &lt;span class="m"&gt;00000004&lt;/span&gt;
         bedae554  b6b40140  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae558  &lt;span class="m"&gt;00000004&lt;/span&gt;
         bedae55c  &lt;span class="m"&gt;00000001&lt;/span&gt;
         bedae560  &lt;span class="m"&gt;00000003&lt;/span&gt;
         bedae564  b6b55300  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae568  b6b556f8  &lt;span class="o"&gt;[&lt;/span&gt;anon:libc_malloc&lt;span class="o"&gt;]&lt;/span&gt;
         bedae56c  b6d53333  /system/lib/libc.so &lt;span class="o"&gt;(&lt;/span&gt;je_tcache_bin_flush_small+210&lt;span class="o"&gt;)&lt;/span&gt;

Tombstone written to: /data/tombstones/tombstone_09
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="ubuntu"></category><category term="android"></category></entry><entry><title>사제 Android Platform SDK 배포시 주의할 점</title><link href="http://ganadist.github.io/2013_01_07_platform_sdk_publish.html" rel="alternate"></link><published>2013-01-07T21:26:00+09:00</published><updated>2013-01-07T21:26:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2013-01-07:/2013_01_07_platform_sdk_publish.html</id><summary type="html">&lt;p&gt;android addon sdk 배포시 주의해야 할&amp;nbsp;사항들&lt;/p&gt;</summary><content type="html">&lt;p&gt;요새 android sdk 및 addon과 관련해서 약간 작업을 하면서 느낀 애로사항을&amp;nbsp;정리해봤습니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;sdk용 addon을 배포하기 위해서는 &lt;a href="http://goo.gl/UUh8a"&gt;xsd 파일&lt;/a&gt;에 정의된 대로 xml을 만들어야&amp;nbsp;합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ics(sdk tools v20)까지 쓰이던 skin이 v21부터 쓰이지 않습니다. 그 대신에 Device Profile이라는 것으로 대체된 것 같습니다. Device Profile은 sdk addon 대신 extra 로 추가될 수 있습니다. (설치 위치가 $&lt;span class="caps"&gt;SDKROOT&lt;/span&gt;/extras/$VENDOR_ID/DeviceProfiles/devices.xml 이면 avd manager에서&amp;nbsp;인식됩니다.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;addon 에 추가되는 문서는 add-ons/addon-blahblah/docs/$DOC_MODULE 로 설치되는데, 실제로 eclipse에서는 add-ons/addon-blahblah/reference 에 설치되어야 IDE와&amp;nbsp;연동됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이건 &lt;a href="http://bugs.sun.com/view_bug.do?bug_id=4787931"&gt;java vm의 버그&lt;/a&gt;인데, java vm에서 사용자 홈 디렉토리를 찾는 부분이 Windows에서는 조금 이상하게 되어 있습니다.
사용자의 바탕화면 폴더를 찾은 다음, 그 윗 폴더를 사용자의 홈 디렉토리(user.home property)로 설정하는데요. 일반적으로는 %&lt;span class="caps"&gt;USERPROFILE&lt;/span&gt;%이라는 환경변수를 사용자 홈 디렉토리로 인지해야 합니다.
그런데 registry등으로 바탕화면 폴더의 위치를 변경 해버리면, Sdk Manager(java app)와 Android Emulator(windows native program)가 찾아보는 HOME디렉토리가 달라지기 때문에 제대로 동작하지 않을 수 있습니다. 간단한 workaround로는 ANDROID_SDK_HOME 이라는 환경변수를 추가적으로 설정해 놓으면, Sdk Manager와 Android Emulator가 엉뚱한 파일을 참조하는 것을 해결할 수&amp;nbsp;있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="android"></category><category term="platform"></category><category term="sdk"></category></entry><entry><title>누가 안드로이드 코드에 기여를 하고 있을까요?</title><link href="http://ganadist.github.io/2013_03_10_who_contribute_aosp.html" rel="alternate"></link><published>2013-01-07T21:26:00+09:00</published><updated>2013-01-07T21:26:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2013-01-07:/2013_03_10_who_contribute_aosp.html</id><summary type="html">&lt;p&gt;안드로이드 오픈소스 프로젝트에 기여하고 있는 사람들&amp;nbsp;살펴보기&lt;/p&gt;</summary><content type="html">&lt;p&gt;실제로 구글에서 안드로이드만 작업하는 외계인들이 얼마나 분포하고 있는지 궁금해서 작은 스크립트를 만들어&amp;nbsp;봤습니다.&lt;/p&gt;
&lt;p&gt;aosp의 커밋로그를 간단하게 긁어서 커밋 작성자의 메일 주소로 googler를 추려낸 다음 커밋 회수를&amp;nbsp;찍어봤는데요.&lt;/p&gt;
&lt;p&gt;일단 안드로이드에 몰빵하는 사람을 추려내는 방법은 제 멋대로 다음을 기준으로&amp;nbsp;잡아봤습니다.,&lt;/p&gt;
&lt;p&gt;200 =~ (2013(올해) - 2008(구글이 안드로이드를 먹은 해) - 1(지금은 연초고 구글이 먹을때는 연말이라 보정)) * (52 * 1) (20% project&amp;nbsp;시간)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;즉 커밋 200개 미만이면 아마 20% 프로젝트동안 삽질한 사람이라 보고 빼는 식으로 하려고 합니다. 그리고 AOSP 전체 소스에서는 약간 여유를 둬서 300커밋 미만으로 짤랐습니다.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;4.2.2를 기준으로 AOSP전체 소스에 300회 이상 커밋한 사람은 111명이고, 그중 코어 모듈(frameworks, bionic, system, hardware, build, dalvik, libcore 디렉토리)에만 커밋회수가 200회 이상인 사람은 68명&amp;nbsp;입니다.&lt;/p&gt;
&lt;p&gt;규모에 비해서 상당히 적은 사람이 일하고 있다는 것을 알 수 있습니다.
(국내 어떤 회사의 꽤 규모가 큰 &lt;span class="caps"&gt;OS&lt;/span&gt; 프로젝트의 경우 풀타임 석박사급 개발자가 200명 이상 투입되었다고 합니다. 그런데 출시도 못하고 접었다는게&amp;nbsp;함정&amp;#8230;)&lt;/p&gt;
&lt;p&gt;그리고 커밋 로그 중 드물게 &lt;code&gt;deckard@android.com&lt;/code&gt; 라는 주소가 보이는데요, 이것은 사람의 메일주소가 아니라 구글 내부 CI시스템입니다. (실제로 https://android-review.googlesource.com 에 코드를 올리면 저 녀석이 해당 코드가 제대로 빌드되는 지&amp;nbsp;확인해줍니다.)&lt;/p&gt;
&lt;p&gt;아마도 영화 블레이드 러너의 주인공인 &lt;a href="http://en.wikipedia.org/wiki/Rick_Deckard"&gt;데커드 형사&lt;/a&gt;의 이름을 딴 것으로&amp;nbsp;보입니다.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/5057717.js?file=getCommitCount.py'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;#!/usr/bin/env python
# -*- coding : utf-8 -*-

import sys, os
import subprocess
import xml.dom.minidom

BOTS = ('initial-contribution@android.com',
	'code-review@android.com',
	'android-gerrit@google.com',
	'android-git-automerger@android.com',
	'android-merger@google.com',
	'deckard@android.com',
)

NOBODY = ('', 'nobody@android.com')

def isBot(email):
	if email in BOTS: return True
	return email.startswith('android-build')

def isGoogler(email):
	if email.endswith('google.com'):
		return True
	if email.endswith('android.com'):
		return True
	return email == ''

def getManifest(path):
	return os.path.join(path, '.repo', 'manifest.xml')

def getTop():
	def isTopDir(path):
		return os.access(getManifest(path), os.F_OK)
		
	def getParents():
		for env in ('TOP', 'ANDROID_BUILD_TOP'):
			wd = os.getenv(env)
			if wd: yield wd
		wd = os.path.abspath(os.getcwd())
		while wd != os.path.sep:
			yield wd
			wd = os.path.dirname(wd)

	for path in getParents():
		if isTopDir(path):
			return path

	assert False, "can not find android source directory."

def getPaths(path):
	manifest = getManifest(path)
	root = xml.dom.minidom.parse(manifest)
	for node in root.childNodes[0].childNodes:
		if node.nodeName != 'project':
			continue
		yield node.getAttribute('path')

def getAuthors(path):
	gitdir = os.path.join(path, '.git')
	cmd = ('git', 'log', '--no-merges', '--pretty=%ae %an')
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE,
			env = {'GIT_DIR': gitdir})
	for line in p.stdout:
		line = line.strip()
		if '@' in line:
			if ' ' in line:
				email, name = line.split(' ', 1)
			else:
				email, name = line, ''
		else:
			email, name = '', line
		yield email, name

class AuthorCount(object):
	def __init__(self, email):
		object.__init__(self)
		self.email = email
		self.names = []
		self.count = 0

	def getName(self):
		return self.names and self.names[0] or ''
	
	def getCount(self):
		return self.count
	
	def getEmail(self):
		return self.email
	
	def incCount(self, name):
		if not name in self.names:
			def nameSort(a, b):
				if a.islower(): return 1
				if b.islower(): return -1
				return cmp(b, a)
			self.names.append(name)
			self.names.sort(nameSort)
		self.count += 1

	def __str__(self):
		if self.email:
			mail = self.email.replace('@', ' at ').replace('.', ' dot ')
		else:
			mail = 'UNKNOWN_AT_GOOGLE_DOT_COM'
		return '%s &lt;%s&gt;\t %d'%(self.getName(), mail, self.count)

if __name__ == '__main__':
	d = {}
	top = getTop()
	platformPrefix = ('frameworks',
			'bionic',
			'system',
			'hardware',
			'build',
			'dalvik',
			'libcore',
	)

	platformOnly = '-p' in sys.argv
	commitCountLimit = platformOnly and 500 or 1000

	def isPlatform(path):
		for prefix in platformPrefix:
			if path.startswith(prefix):
				return True

	for path in getPaths(top):
		if platformOnly and not isPlatform(path):
			continue

		for author in getAuthors(path):
			email, name = author
			if isBot(email):
				continue
			if not isGoogler(email):
				continue
			if email in NOBODY:
				key = 'NOBODY', name
				email = ''
			else:
				if email.endswith('corp.google.com'):
					email = email.split('@', 1)[0] + '@google.com'
				key = email, ''
			d.setdefault(key, AuthorCount(email)).incCount(name)

	names = {}
	for item in d.iteritems():
		k, v = item
		name = v.getName()
		names.setdefault(name, set()).add(item)

	# get delegate account in duplicated
	def getDelegates(items):
		google_account = set()
		android_account = set()
		for key, value in items:
			email = value.getEmail()
			if email.endswith('google.com'):
				google_account.add((key, value))
			elif email.endswith('android.com'):
				android_account.add((key, value))
		return google_account and google_account or android_account

	# merge duplicated account
	for items in names.itervalues():
		if len(items) == 1: continue
		delegates = getDelegates(items)
		if len(delegates) != 1: continue
		delegate = tuple(delegates)[0][1]
		for k, v in items - delegates:
			del d[k]
			delegate.count += v.count

	countKey = lambda x:x.getCount()
	nameKey = lambda x:x.getName()
	emailKey = lambda x:x.getEmail()

	count = 0
	for item in sorted(d.itervalues(), key = countKey):
		#if d[item].count &lt; commitCountLimit: continue
		sys.stdout.write('%s\n'%(str(item)))
		count += item.getCount()
	print 'total commit count:', count&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;https://gist.github.com/ganadist/5057717&lt;/p&gt;</content><category term="android"></category><category term="platform"></category><category term="opensource"></category></entry><entry><title>간단하게 뜯어보는 nbd(network block device)</title><link href="http://ganadist.github.io/2011_08_15_nbd.html" rel="alternate"></link><published>2011-08-15T12:00:00+09:00</published><updated>2011-08-15T12:00:00+09:00</updated><author><name>YOUNG HO CHA</name></author><id>tag:ganadist.github.io,2011-08-15:/2011_08_15_nbd.html</id><summary type="html">&lt;p&gt;nbd&amp;nbsp;사용방법&lt;/p&gt;</summary><content type="html">&lt;p&gt;nbd는 소켓을 이용해서 저멀리 떨어져있는 기계의 block장치를 현재 컴퓨터의 block장치처럼 쓰게 하는 리눅스의&amp;nbsp;기능이다.&lt;/p&gt;
&lt;p&gt;물론 꼭 저 멀리 떨어져있을 필요는 없으며, 꼭 block장치여야 한다는 법은&amp;nbsp;없다.&lt;/p&gt;
&lt;p&gt;특정한 위치에서 특정한 길이의 데이터를 read하거나 write할 수만 있으면&amp;nbsp;상관없다.&lt;/p&gt;
&lt;p&gt;nbd를 구성하려면 3개의 컴퍼넌트가&amp;nbsp;필요하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nbd&amp;nbsp;커널드라이버&lt;/li&gt;
&lt;li&gt;nbd&amp;nbsp;서버&lt;/li&gt;
&lt;li&gt;nbd&amp;nbsp;클라이언트&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;nbd&amp;nbsp;커널드라이버&lt;/h2&gt;
&lt;p&gt;커널의 block devices 설정에 포함되어으며, 이 설정을 켜놓으면 /dev/nbd[0-7] 또는 /dev/block/nbd[0-7] 장치로 유저스페이스에&amp;nbsp;노출된다.&lt;/p&gt;
&lt;h2&gt;nbd&amp;nbsp;클라이언트&lt;/h2&gt;
&lt;p&gt;nbd서버와 연결한 소켓을 nbd device 장치와 연결해주는 역할을&amp;nbsp;한다.&lt;/p&gt;
&lt;p&gt;그외에 블럭장치의 특성(block 장치의 크기, block size, timeout, 등)을 설정해야&amp;nbsp;한다.&lt;/p&gt;
&lt;p&gt;해당 설정은 &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/uapi/linux/nbd.h?h=v4.16#n21"&gt;ioctl 명령&lt;/a&gt; 을&amp;nbsp;참조.&lt;/p&gt;
&lt;h2&gt;nbd&amp;nbsp;서버&lt;/h2&gt;
&lt;p&gt;nbd 드라이버에서 보낸 요청을 처리하는&amp;nbsp;서버&lt;/p&gt;
&lt;p&gt;nbd의 요청은 &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/uapi/linux/nbd.h?h=v4.16#n66"&gt;다음과 같은 형태&lt;/a&gt;로&amp;nbsp;전달된다.&lt;/p&gt;
&lt;p&gt;각각의 의미는 다음과&amp;nbsp;같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;magic: nbd request의 시작. NBD_REQUEST_MAGIC값과 동일해야 한다. 이 값이 틀리면 깨지거나 잘못된&amp;nbsp;패킷이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type: 읽기/쓰기 요청의&amp;nbsp;구분&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;handle: 각 요청을 구분하기 위한 값. nbd_reply에 이 값을 복사해서 응답해야&amp;nbsp;한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;from: 읽기/쓰기를 시작할&amp;nbsp;offset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;len: 읽기/쓰기를 할&amp;nbsp;길이&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;쓰기 request일 경우, 위 요청 패킷 바로 뒤에 len에 해당하는 길이의 데이터가 덧붙여&amp;nbsp;따라온다.&lt;/p&gt;
&lt;p&gt;nbd의 요청에 대한 응답은 다음과&amp;nbsp;같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;magic: nbd reply의 시작. NBD_REPLY_MAGIC값을 채워야&amp;nbsp;한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;error: 오류 발생시 적절한 errno를 채운다. (보통은 &lt;span class="caps"&gt;EIO&lt;/span&gt;). 에러가 없을 때는 0을&amp;nbsp;채운다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;handle: nbd_request의 handle값을&amp;nbsp;복사한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;읽기 request일 경우, 위 응답 패킷을 보낸 후 요청 길이만큼 데이터를 덧붙여 보내면&amp;nbsp;된다.&lt;/p&gt;
&lt;p&gt;위의 모든 값은 모두 Network byte order로 변환해서 처리해야&amp;nbsp;한다.&lt;/p&gt;
&lt;p&gt;자세한건 &lt;a href="http://nbd.sourceforge.net"&gt;nbd 홈페이지&lt;/a&gt;의 client/server 코드를&amp;nbsp;참조.&lt;/p&gt;
&lt;p&gt;그리고 위의 server/client는 &lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt; 소켓으로 구현되어 있지만, 리눅스에서 지원하는 SOCK_STREAM 타입의 소켓이라면 어느것이라도 지원된다. (유닉스 도메인 소켓이나 블루투스, &lt;span class="caps"&gt;IRDA&lt;/span&gt;&amp;nbsp;등등) &lt;/p&gt;</content><category term="linux"></category></entry></feed>